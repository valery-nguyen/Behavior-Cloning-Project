{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "File structure\n",
    "Folder and files in main directory:\n",
    "- model.py\n",
    "- Behavior-Cloning.ipynb\n",
    "- model.json\n",
    "- model.h5\n",
    "- drive.py\n",
    "- driving_log.csv\n",
    "- 'IMG' folder\n",
    "    -- 'All .jpg images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('c:\\\\users\\\\valery\\\\miniconda3\\\\envs\\\\tensorflow-gpu\\\\Lib\\\\site-packages')\n",
    "sys.path.append('c:\\\\users\\\\valery\\\\miniconda3\\\\envs\\\\tensorflow-gpu\\\\Lib\\\\site-packages\\\\sklearn\\\\feature_extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get training dataset from Udacity website\n",
    "\n",
    "# Imports\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('driving_log.csv'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Train Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip',\n",
    "            'data.zip',\n",
    "            pbar.hook)\n",
    "\n",
    "    # Unzip data set\n",
    "    zip_ref = zipfile.ZipFile('data.zip', 'r')\n",
    "    zip_ref.extractall('')\n",
    "    zip_ref.close()\n",
    "\n",
    "    # Move dataset to folder location\n",
    "    shutil.move('data/IMG/','IMG')\n",
    "    shutil.move('data/driving_log.csv','driving_log.csv')\n",
    "    \n",
    "    print('Training data downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Fix error with TF and Keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Sources: https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py\"\"\"\n",
    "\n",
    "# Preprocessing functions for image set\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# Shuffle image set\n",
    "def shuffle_set(all_angles, imgs_fname):\n",
    "    return shuffle(all_angles, imgs_fname)\n",
    "\n",
    "# Preprocess image\n",
    "def preprocess_img(img,angle):  \n",
    "    img = np.squeeze(img)\n",
    "    img = yuv_img(img)\n",
    "    img = crop_img(img)\n",
    "    img = resize_img(img)\n",
    "    img,angle_p = random_transform(img,angle)\n",
    "    img_p = np.expand_dims(img, axis=0)\n",
    "    return img_p,angle_p\n",
    "\n",
    "# Transform BGR to YUV\n",
    "def yuv_img(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "# Crop image\n",
    "def crop_img(img):\n",
    "    y1,y2,x1,x2 = 60,120,0,320\n",
    "    return img[y1:y2,x1:x2]\n",
    "\n",
    "# Resize image\n",
    "def resize_img(img):\n",
    "    return cv2.resize(img,(img_length,img_height))\n",
    "\n",
    "# Random transform to image\n",
    "def random_transform(img, angle):\n",
    "    \n",
    "    img_row_axis = 0\n",
    "    img_col_axis = 1\n",
    "    img_channel_axis = 2\n",
    "\n",
    "    # Rotation\n",
    "    rotation_range = 15\n",
    "    theta = np.pi / 180 * np.random.uniform(-rotation_range, rotation_range)\n",
    "    \n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n",
    "                                [np.sin(theta), np.cos(theta), 0],\n",
    "                                [0, 0, 1]])\n",
    "    angle = angle + theta/2\n",
    "\n",
    "    \n",
    "    # Shift horizontal and vertical\n",
    "    height_shift_range = 0.3\n",
    "    tx = np.random.uniform(-height_shift_range, height_shift_range) * img.shape[img_row_axis]\n",
    "    \n",
    "    width_shift_range = 0.3\n",
    "    ty = np.random.uniform(-width_shift_range, width_shift_range) * img.shape[img_col_axis]\n",
    "    \n",
    "    translation_matrix = np.array([[1, 0, tx],\n",
    "                                   [0, 1, ty],\n",
    "                                   [0, 0, 1]])\n",
    "\n",
    "    angle = angle + math.atan(-ty/(img.shape[img_row_axis]+tx))\n",
    "    \n",
    "    # Transformation\n",
    "    h, w = img.shape[img_row_axis], img.shape[img_col_axis]\n",
    "    \n",
    "    transform_matrix = np.dot(rotation_matrix,translation_matrix)\n",
    "    transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n",
    "    img = apply_transform(img, transform_matrix, img_channel_axis)\n",
    "    \n",
    "    # Horizontal flip\n",
    "    if np.random.random() < 0.5:\n",
    "        img = flip_axis(img, img_col_axis)\n",
    "        angle = -1 * angle\n",
    "        \n",
    "    return img, angle\n",
    "        \n",
    "\n",
    "def transform_matrix_offset_center(matrix, x, y):\n",
    "    o_x = float(x) / 2 + 0.5\n",
    "    o_y = float(y) / 2 + 0.5\n",
    "    offset_matrix = np.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])\n",
    "    reset_matrix = np.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])\n",
    "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
    "    \n",
    "    return transform_matrix\n",
    "    \n",
    "\n",
    "def apply_transform(x, transform_matrix, channel_axis=0, fill_mode='nearest', cval=0.):\n",
    "    x = np.rollaxis(x, channel_axis, 0)\n",
    "    final_affine_matrix = transform_matrix[:2, :2]\n",
    "    final_offset = transform_matrix[:2, 2]\n",
    "    channel_images = [ndi.interpolation.affine_transform(x_channel, final_affine_matrix,\n",
    "                                                         final_offset, order=0, mode=fill_mode, cval=cval) for x_channel in x]\n",
    "    x = np.stack(channel_images, axis=0)\n",
    "    x = np.rollaxis(x, 0, channel_axis + 1)\n",
    "\n",
    "    return x\n",
    "\n",
    "def flip_axis(x, axis):\n",
    "    x = np.asarray(x).swapaxes(axis, 0)\n",
    "    x = x[::-1, ...]\n",
    "    x = x.swapaxes(0, axis)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All angles data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load and one-hot all angles (labels)\n",
    "\n",
    "# Imports\n",
    "import csv, sys\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "filename = 'driving_log.csv'\n",
    "all_angles = []\n",
    "imgs_fname = []\n",
    "\n",
    "with open(filename, 'rt') as csvfile:\n",
    "    \n",
    "    # Load driving angle data\n",
    "    anglereader = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "    try:\n",
    "        for row in anglereader:\n",
    "            all_angles.append(float(row[-4]))\n",
    "          \n",
    "            fln = row[0].split('/')\n",
    "            imgs_fname.append(fln[-1])\n",
    "    except csv.Error as e:\n",
    "        sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Total number of unique angles data\n",
    "    num_uniq_ang = len(np.unique(all_angles))    \n",
    "    num_all_ang = len(all_angles)  \n",
    "            \n",
    "    # Shuffle data set\n",
    "    all_angles, imgs_fname = shuffle_set(all_angles, imgs_fname)\n",
    "    \n",
    "print('All angles data loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load images and driving log data for each batch\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Total number of images\n",
    "num_all_img = len(os.listdir(os.getcwd()+'/IMG'))\n",
    "\n",
    "def load_data_batch(batch_num,batch_size,all_angles, imgs_fname, img_height, img_length):\n",
    "    \n",
    "    img_folder_path = os.getcwd()+'\\\\IMG'\n",
    "    valid_ext = [\".jpg\"]\n",
    "\n",
    "    imgs = np.empty((0,img_height,img_length,3))\n",
    "    angles = []\n",
    "    angles = all_angles[batch_num*batch_size:(batch_num+1)*batch_size]\n",
    "    imgs_fname_batch  = imgs_fname[batch_num*batch_size:(batch_num+1)*batch_size]\n",
    "    \n",
    "    for f in imgs_fname_batch:\n",
    "        img_path = os.path.join(img_folder_path,f)\n",
    "        img = Image.open(img_path)\n",
    "        img,angles[imgs.shape[0]] = preprocess_img(img,angles[imgs.shape[0]])\n",
    "        imgs = np.append(imgs,img,axis=0)\n",
    "\n",
    "    imgs = imgs.astype(np.uint8)\n",
    "\n",
    "    return imgs, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define train and validation batch generators\n",
    "\n",
    "# Imports\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Hyper Parameters\n",
    "epoch = 1\n",
    "\n",
    "# Pick samples per epoch = num_all_ang\n",
    "samples_per_epoch = math.floor(num_all_ang/64)*64\n",
    "\n",
    "# Pick batch_size = 64\n",
    "batch_size = 64\n",
    "\n",
    "train_valid_split = 0.8\n",
    "nb_val_samples = samples_per_epoch*(1-train_valid_split)\n",
    "\n",
    "# Resized image shape\n",
    "img_height = 64\n",
    "img_length = 64\n",
    "img_ch = 3\n",
    "\n",
    "# Batch parameters\n",
    "batch_train_max = math.floor(train_valid_split*num_all_ang/batch_size)\n",
    "batch_validation_max = math.floor(num_all_ang/batch_size)\n",
    "nb_val_samples = math.floor((1-train_valid_split)*num_all_ang)\n",
    "\n",
    "def generate_train_batch(batch_size):\n",
    "    # Generate data batch\n",
    "    while 1:\n",
    "        for batch_num in range (0,batch_train_max):\n",
    "            X_train_ba, y_train_ba = load_data_batch(batch_num,batch_size,\n",
    "                                                     all_angles,imgs_fname,\n",
    "                                                     img_height,img_length)\n",
    "            if batch_num == (batch_train_max-1):\n",
    "                batch_num = 0\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            yield X_train_ba, y_train_ba\n",
    "\n",
    "def generate_validation_batch(batch_size):\n",
    "    # Generate data batch\n",
    "    batch_range = batch_validation_max - batch_train_max\n",
    "    while 1:\n",
    "        for batch_num in range (0,batch_range):\n",
    "            batch_val_num = batch_num + batch_train_max\n",
    "\n",
    "            X_validation_ba, y_validation_ba = load_data_batch(batch_num,batch_size,\n",
    "                                                               all_angles,imgs_fname,\n",
    "                                                               img_height, img_length)          \n",
    "            if batch_num == (batch_range-1):\n",
    "                batch_num = 0\n",
    "            \n",
    "            yield X_validation_ba, y_validation_ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CHOOSE TO IMPORT MODEL AND WEIGHTS\n",
    "# OPTIONAL: import model_train.json and model_train.h5\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model from model.json\n",
    "json_data=open('model.json').read()\n",
    "json_string = json.loads(json_data)\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "#Load the weights from model.h5\n",
    "model.load_weights('model.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\"\"\"\n",
    "sources:\n",
    "https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda, Dense, Activation, Dropout, Flatten \n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "row, col, ch = img_height,img_length,img_ch\n",
    "\n",
    "#nvidia model\n",
    "model = Sequential()               \n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "                 input_shape=(row,col,ch),\n",
    "                 output_shape=(row,col,ch)))\n",
    "\n",
    "model.add(Convolution2D(24,5,5,border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "\n",
    "model.add(Convolution2D(36,5,5,border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "\n",
    "model.add(Convolution2D(48,5,5,border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "\n",
    "model.add(Convolution2D(64,3,3,border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "\n",
    "model.add(Convolution2D(64,3,3,border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(1,1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1164))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 64, 64, 3)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 64, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 64, 64, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 63, 63, 24)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 63, 63, 36)    21636       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 63, 63, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 62, 62, 36)    0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 62, 62, 48)    43248       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 62, 62, 48)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 61, 61, 48)    0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 61, 61, 64)    27712       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 61, 61, 64)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 60, 60, 64)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 60, 60, 64)    36928       maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 60, 60, 64)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 59, 59, 64)    0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 222784)        0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 222784)        0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 222784)        0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1164)          259321740   activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1164)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 1164)          0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 100)           116500      activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 100)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 100)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 50)            5050        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 50)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 50)            0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            510         activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 10)            0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 10)            0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             11          activation_10[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 259,575,159\n",
      "Trainable params: 259,575,159\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   64/24064 [..............................] - ETA: 8278s - loss: 0.0145\n",
      "\n",
      "\n",
      "  128/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 7562s - loss: 0.0210\n",
      "  192/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 7408s - loss: 0.0200\n",
      "  256/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 7320s - loss: 0.0203\n",
      "  320/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 7181s - loss: 0.0208\n",
      "  384/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 7084s - loss: 0.0223\n",
      "  448/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6941s - loss: 0.0239\n",
      "  512/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6861s - loss: 0.0246\n",
      "  576/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6789s - loss: 0.0250\n",
      "  640/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6750s - loss: 0.0261\n",
      "  704/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6706s - loss: 0.0253\n",
      "  768/24064 [..............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6668s - loss: 0.0254\n",
      "  832/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6627s - loss: 0.0259\n",
      "  896/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6619s - loss: 0.0256\n",
      "  960/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6569s - loss: 0.0256\n",
      " 1024/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6533s - loss: 0.0258\n",
      " 1088/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6516s - loss: 0.0258\n",
      " 1152/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6484s - loss: 0.0254\n",
      " 1216/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6455s - loss: 0.0258\n",
      " 1280/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6426s - loss: 0.0253\n",
      " 1344/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6401s - loss: 0.0250\n",
      " 1408/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6370s - loss: 0.0251\n",
      " 1472/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6345s - loss: 0.0252\n",
      " 1536/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6323s - loss: 0.0252\n",
      " 1600/24064 [>.............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6307s - loss: 0.0252\n",
      " 1664/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6285s - loss: 0.0251\n",
      " 1728/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6261s - loss: 0.0251\n",
      " 1792/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6239s - loss: 0.0253\n",
      " 1856/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6195s - loss: 0.0251\n",
      " 1920/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6153s - loss: 0.0253\n",
      " 1984/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6111s - loss: 0.0255\n",
      " 2048/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6073s - loss: 0.0254\n",
      " 2112/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6045s - loss: 0.0256\n",
      " 2176/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 6012s - loss: 0.0255\n",
      " 2240/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5977s - loss: 0.0252\n",
      " 2304/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5949s - loss: 0.0252\n",
      " 2368/24064 [=>............................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5918s - loss: 0.0249\n",
      " 2432/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5885s - loss: 0.0249\n",
      " 2496/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5851s - loss: 0.0249\n",
      " 2560/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5827s - loss: 0.0247\n",
      " 2624/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5792s - loss: 0.0246\n",
      " 2688/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5763s - loss: 0.0247\n",
      " 2752/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5733s - loss: 0.0249\n",
      " 2816/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5707s - loss: 0.0250\n",
      " 2880/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5680s - loss: 0.0249\n",
      " 2944/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5643s - loss: 0.0250\n",
      " 3008/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5614s - loss: 0.0249\n",
      " 3072/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5581s - loss: 0.0249\n",
      " 3136/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5560s - loss: 0.0246\n",
      " 3200/24064 [==>...........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5540s - loss: 0.0247\n",
      " 3264/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5510s - loss: 0.0249\n",
      " 3328/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5488s - loss: 0.0249\n",
      " 3392/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5458s - loss: 0.0248\n",
      " 3456/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5433s - loss: 0.0246\n",
      " 3520/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5413s - loss: 0.0247\n",
      " 3584/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5389s - loss: 0.0247\n",
      " 3648/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5370s - loss: 0.0248\n",
      " 3712/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5339s - loss: 0.0250\n",
      " 3776/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5317s - loss: 0.0251\n",
      " 3840/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5293s - loss: 0.0250\n",
      " 3904/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5272s - loss: 0.0248\n",
      " 3968/24064 [===>..........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5250s - loss: 0.0249\n",
      " 4032/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5229s - loss: 0.0247\n",
      " 4096/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5209s - loss: 0.0247\n",
      " 4160/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5187s - loss: 0.0248\n",
      " 4224/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5166s - loss: 0.0248\n",
      " 4288/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5141s - loss: 0.0249\n",
      " 4352/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5119s - loss: 0.0250\n",
      " 4416/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5094s - loss: 0.0250\n",
      " 4480/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5069s - loss: 0.0251\n",
      " 4544/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5048s - loss: 0.0250\n",
      " 4608/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5024s - loss: 0.0251\n",
      " 4672/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 5004s - loss: 0.0253\n",
      " 4736/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4986s - loss: 0.0254\n",
      " 4800/24064 [====>.........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4962s - loss: 0.0255\n",
      " 4864/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4941s - loss: 0.0254\n",
      " 4928/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4921s - loss: 0.0254\n",
      " 4992/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4903s - loss: 0.0256\n",
      " 5056/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4884s - loss: 0.0256\n",
      " 5120/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4862s - loss: 0.0256\n",
      " 5184/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4845s - loss: 0.0255\n",
      " 5248/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4828s - loss: 0.0255\n",
      " 5312/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4811s - loss: 0.0255\n",
      " 5376/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4793s - loss: 0.0255\n",
      " 5440/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4777s - loss: 0.0255\n",
      " 5504/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4760s - loss: 0.0255\n",
      " 5568/24064 [=====>........................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4741s - loss: 0.0256\n",
      " 5632/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4717s - loss: 0.0256\n",
      " 5696/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4700s - loss: 0.0255\n",
      " 5760/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4681s - loss: 0.0255\n",
      " 5824/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4663s - loss: 0.0254\n",
      " 5888/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4644s - loss: 0.0255\n",
      " 5952/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4626s - loss: 0.0255\n",
      " 6016/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4606s - loss: 0.0254\n",
      " 6080/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4588s - loss: 0.0254\n",
      " 6144/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4568s - loss: 0.0255\n",
      " 6208/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4550s - loss: 0.0256\n",
      " 6272/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4529s - loss: 0.0255\n",
      " 6336/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4510s - loss: 0.0256\n",
      " 6400/24064 [======>.......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4491s - loss: 0.0256\n",
      " 6464/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4472s - loss: 0.0257\n",
      " 6528/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4454s - loss: 0.0256\n",
      " 6592/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4434s - loss: 0.0256\n",
      " 6656/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4416s - loss: 0.0255\n",
      " 6720/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4400s - loss: 0.0255\n",
      " 6784/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4381s - loss: 0.0254\n",
      " 6848/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4364s - loss: 0.0254\n",
      " 6912/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4346s - loss: 0.0255\n",
      " 6976/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4327s - loss: 0.0255\n",
      " 7040/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4309s - loss: 0.0254\n",
      " 7104/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4291s - loss: 0.0254\n",
      " 7168/24064 [=======>......................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4274s - loss: 0.0253\n",
      " 7232/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4258s - loss: 0.0253\n",
      " 7296/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4240s - loss: 0.0253\n",
      " 7360/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4222s - loss: 0.0253\n",
      " 7424/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4204s - loss: 0.0254\n",
      " 7488/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4188s - loss: 0.0253\n",
      " 7552/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4168s - loss: 0.0253\n",
      " 7616/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4151s - loss: 0.0254\n",
      " 7680/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4132s - loss: 0.0256\n",
      " 7744/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4115s - loss: 0.0255\n",
      " 7808/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4097s - loss: 0.0255\n",
      " 7872/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4081s - loss: 0.0255\n",
      " 7936/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4063s - loss: 0.0255\n",
      " 8000/24064 [========>.....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4045s - loss: 0.0255\n",
      " 8064/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4028s - loss: 0.0255\n",
      " 8128/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 4011s - loss: 0.0254\n",
      " 8192/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3993s - loss: 0.0254\n",
      " 8256/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3975s - loss: 0.0253\n",
      " 8320/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3958s - loss: 0.0254\n",
      " 8384/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3940s - loss: 0.0254\n",
      " 8448/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3924s - loss: 0.0253\n",
      " 8512/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3908s - loss: 0.0254\n",
      " 8576/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3891s - loss: 0.0254\n",
      " 8640/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3873s - loss: 0.0253\n",
      " 8704/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3856s - loss: 0.0253\n",
      " 8768/24064 [=========>....................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3839s - loss: 0.0253\n",
      " 8832/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3821s - loss: 0.0253\n",
      " 8896/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3805s - loss: 0.0253\n",
      " 8960/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3788s - loss: 0.0253\n",
      " 9024/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3771s - loss: 0.0253\n",
      " 9088/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3755s - loss: 0.0252\n",
      " 9152/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3737s - loss: 0.0253\n",
      " 9216/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3720s - loss: 0.0252\n",
      " 9280/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3704s - loss: 0.0252\n",
      " 9344/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3688s - loss: 0.0252\n",
      " 9408/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3671s - loss: 0.0252\n",
      " 9472/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3656s - loss: 0.0252\n",
      " 9536/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3639s - loss: 0.0252\n",
      " 9600/24064 [==========>...................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3622s - loss: 0.0252\n",
      " 9664/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3607s - loss: 0.0251\n",
      " 9728/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3590s - loss: 0.0252\n",
      " 9792/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3573s - loss: 0.0251\n",
      " 9856/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3558s - loss: 0.0251\n",
      " 9920/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3541s - loss: 0.0252\n",
      " 9984/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3525s - loss: 0.0252\n",
      "10048/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3509s - loss: 0.0252\n",
      "10112/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3492s - loss: 0.0251\n",
      "10176/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3475s - loss: 0.0252\n",
      "10240/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3459s - loss: 0.0252\n",
      "10304/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3443s - loss: 0.0252\n",
      "10368/24064 [===========>..................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3426s - loss: 0.0252\n",
      "10432/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3411s - loss: 0.0252\n",
      "10496/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3393s - loss: 0.0252\n",
      "10560/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3377s - loss: 0.0251\n",
      "10624/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3362s - loss: 0.0251\n",
      "10688/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3345s - loss: 0.0251\n",
      "10752/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3328s - loss: 0.0251\n",
      "10816/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3312s - loss: 0.0251\n",
      "10880/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3295s - loss: 0.0252\n",
      "10944/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3279s - loss: 0.0252\n",
      "11008/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3262s - loss: 0.0253\n",
      "11072/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3245s - loss: 0.0252\n",
      "11136/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3229s - loss: 0.0252\n",
      "11200/24064 [============>.................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3213s - loss: 0.0252\n",
      "11264/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3197s - loss: 0.0253\n",
      "11328/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3181s - loss: 0.0253\n",
      "11392/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3165s - loss: 0.0254\n",
      "11456/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3149s - loss: 0.0254\n",
      "11520/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3133s - loss: 0.0255\n",
      "11584/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3116s - loss: 0.0255\n",
      "11648/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3099s - loss: 0.0254\n",
      "11712/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3083s - loss: 0.0254\n",
      "11776/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3066s - loss: 0.0255\n",
      "11840/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3049s - loss: 0.0255\n",
      "11904/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3032s - loss: 0.0254\n",
      "11968/24064 [=============>................]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3016s - loss: 0.0254\n",
      "12032/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 3000s - loss: 0.0254\n",
      "12096/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2983s - loss: 0.0254\n",
      "12160/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2967s - loss: 0.0253\n",
      "12224/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2950s - loss: 0.0253\n",
      "12288/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2934s - loss: 0.0253\n",
      "12352/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2918s - loss: 0.0252\n",
      "12416/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2902s - loss: 0.0252\n",
      "12480/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2885s - loss: 0.0253\n",
      "12544/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2868s - loss: 0.0253\n",
      "12608/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2851s - loss: 0.0253\n",
      "12672/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2835s - loss: 0.0253\n",
      "12736/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2819s - loss: 0.0253\n",
      "12800/24064 [==============>...............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2803s - loss: 0.0253\n",
      "12864/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2786s - loss: 0.0253\n",
      "12928/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2770s - loss: 0.0253\n",
      "12992/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2754s - loss: 0.0252\n",
      "13056/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2738s - loss: 0.0253\n",
      "13120/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2721s - loss: 0.0253\n",
      "13184/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2705s - loss: 0.0253\n",
      "13248/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2689s - loss: 0.0253\n",
      "13312/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2673s - loss: 0.0253\n",
      "13376/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2657s - loss: 0.0253\n",
      "13440/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2641s - loss: 0.0253\n",
      "13504/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2625s - loss: 0.0253\n",
      "13568/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2609s - loss: 0.0253\n",
      "13632/24064 [===============>..............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2592s - loss: 0.0253\n",
      "13696/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2576s - loss: 0.0253\n",
      "13760/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2560s - loss: 0.0253\n",
      "13824/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2544s - loss: 0.0253\n",
      "13888/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2528s - loss: 0.0253\n",
      "13952/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2512s - loss: 0.0253\n",
      "14016/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2496s - loss: 0.0253\n",
      "14080/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2480s - loss: 0.0253\n",
      "14144/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2463s - loss: 0.0253\n",
      "14208/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2447s - loss: 0.0253\n",
      "14272/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2431s - loss: 0.0252\n",
      "14336/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2415s - loss: 0.0252\n",
      "14400/24064 [================>.............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2398s - loss: 0.0252\n",
      "14464/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2382s - loss: 0.0252\n",
      "14528/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2365s - loss: 0.0252\n",
      "14592/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2349s - loss: 0.0252\n",
      "14656/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2332s - loss: 0.0252\n",
      "14720/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2316s - loss: 0.0252\n",
      "14784/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2300s - loss: 0.0252\n",
      "14848/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2284s - loss: 0.0252\n",
      "14912/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2267s - loss: 0.0253\n",
      "14976/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2251s - loss: 0.0253\n",
      "15040/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2235s - loss: 0.0253\n",
      "15104/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2219s - loss: 0.0253\n",
      "15168/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2202s - loss: 0.0253\n",
      "15232/24064 [=================>............]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2186s - loss: 0.0254\n",
      "15296/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2170s - loss: 0.0254\n",
      "15360/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2154s - loss: 0.0254\n",
      "15424/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2138s - loss: 0.0254\n",
      "15488/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2122s - loss: 0.0254\n",
      "15552/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2106s - loss: 0.0253\n",
      "15616/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2089s - loss: 0.0253\n",
      "15680/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2073s - loss: 0.0253\n",
      "15744/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2057s - loss: 0.0253\n",
      "15808/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2041s - loss: 0.0253\n",
      "15872/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2025s - loss: 0.0254\n",
      "15936/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 2010s - loss: 0.0254\n",
      "16000/24064 [==================>...........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1993s - loss: 0.0253\n",
      "16064/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1977s - loss: 0.0254\n",
      "16128/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1961s - loss: 0.0254\n",
      "16192/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1945s - loss: 0.0255\n",
      "16256/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1929s - loss: 0.0254\n",
      "16320/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1913s - loss: 0.0254\n",
      "16384/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1897s - loss: 0.0254\n",
      "16448/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1881s - loss: 0.0254\n",
      "16512/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1865s - loss: 0.0254\n",
      "16576/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1849s - loss: 0.0254\n",
      "16640/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1833s - loss: 0.0254\n",
      "16704/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1818s - loss: 0.0254\n",
      "16768/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1801s - loss: 0.0254\n",
      "16832/24064 [===================>..........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1785s - loss: 0.0254\n",
      "16896/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1770s - loss: 0.0254\n",
      "16960/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1754s - loss: 0.0254\n",
      "17024/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1738s - loss: 0.0254\n",
      "17088/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1722s - loss: 0.0254\n",
      "17152/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1707s - loss: 0.0254\n",
      "17216/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1691s - loss: 0.0254\n",
      "17280/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1675s - loss: 0.0254\n",
      "17344/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1659s - loss: 0.0254\n",
      "17408/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1644s - loss: 0.0254\n",
      "17472/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1628s - loss: 0.0254\n",
      "17536/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1612s - loss: 0.0254\n",
      "17600/24064 [====================>.........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1596s - loss: 0.0255\n",
      "17664/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1581s - loss: 0.0255\n",
      "17728/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1565s - loss: 0.0254\n",
      "17792/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1548s - loss: 0.0254\n",
      "17856/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1533s - loss: 0.0254\n",
      "17920/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1517s - loss: 0.0254\n",
      "17984/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1500s - loss: 0.0254\n",
      "18048/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1485s - loss: 0.0254\n",
      "18112/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1468s - loss: 0.0255\n",
      "18176/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1453s - loss: 0.0254\n",
      "18240/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1437s - loss: 0.0254\n",
      "18304/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1421s - loss: 0.0254\n",
      "18368/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1405s - loss: 0.0254\n",
      "18432/24064 [=====================>........]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1389s - loss: 0.0254\n",
      "18496/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1373s - loss: 0.0254\n",
      "18560/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1357s - loss: 0.0254\n",
      "18624/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1341s - loss: 0.0254\n",
      "18688/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1325s - loss: 0.0254\n",
      "18752/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1309s - loss: 0.0254\n",
      "18816/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1293s - loss: 0.0254\n",
      "18880/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1277s - loss: 0.0254\n",
      "18944/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1261s - loss: 0.0254\n",
      "19008/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1245s - loss: 0.0254\n",
      "19072/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1229s - loss: 0.0254\n",
      "19136/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1213s - loss: 0.0254\n",
      "19200/24064 [======================>.......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1198s - loss: 0.0254\n",
      "19264/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1182s - loss: 0.0254\n",
      "19328/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1166s - loss: 0.0254\n",
      "19392/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1150s - loss: 0.0254\n",
      "19456/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1134s - loss: 0.0254\n",
      "19520/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1119s - loss: 0.0254\n",
      "19584/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1103s - loss: 0.0254\n",
      "19648/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1087s - loss: 0.0254\n",
      "19712/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1071s - loss: 0.0254\n",
      "19776/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1055s - loss: 0.0254\n",
      "19840/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1040s - loss: 0.0254\n",
      "19904/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1024s - loss: 0.0255\n",
      "19968/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 1008s - loss: 0.0255\n",
      "20032/24064 [=======================>......]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 992s - loss: 0.0255 \n",
      "20096/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 976s - loss: 0.0256\n",
      "20160/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 960s - loss: 0.0256\n",
      "20224/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 944s - loss: 0.0256\n",
      "20288/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 929s - loss: 0.0256\n",
      "20352/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 913s - loss: 0.0256\n",
      "20416/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 897s - loss: 0.0255\n",
      "20480/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 881s - loss: 0.0255\n",
      "20544/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 865s - loss: 0.0256\n",
      "20608/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 849s - loss: 0.0256\n",
      "20672/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 834s - loss: 0.0256\n",
      "20736/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 818s - loss: 0.0256\n",
      "20800/24064 [========================>.....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 802s - loss: 0.0256\n",
      "20864/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 787s - loss: 0.0256\n",
      "20928/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 771s - loss: 0.0256\n",
      "20992/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 755s - loss: 0.0256\n",
      "21056/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 739s - loss: 0.0257\n",
      "21120/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 723s - loss: 0.0256\n",
      "21184/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 707s - loss: 0.0256\n",
      "21248/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 692s - loss: 0.0256\n",
      "21312/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 676s - loss: 0.0256\n",
      "21376/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 660s - loss: 0.0256\n",
      "21440/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 644s - loss: 0.0256\n",
      "21504/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 629s - loss: 0.0256\n",
      "21568/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 613s - loss: 0.0256\n",
      "21632/24064 [=========================>....]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 597s - loss: 0.0256\n",
      "21696/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 581s - loss: 0.0256\n",
      "21760/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 566s - loss: 0.0256\n",
      "21824/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 550s - loss: 0.0256\n",
      "21888/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 534s - loss: 0.0256\n",
      "21952/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 518s - loss: 0.0256\n",
      "22016/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 503s - loss: 0.0256\n",
      "22080/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 487s - loss: 0.0256\n",
      "22144/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 471s - loss: 0.0257\n",
      "22208/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 455s - loss: 0.0257\n",
      "22272/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 440s - loss: 0.0257\n",
      "22336/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 424s - loss: 0.0257\n",
      "22400/24064 [==========================>...]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 408s - loss: 0.0257\n",
      "22464/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 392s - loss: 0.0257\n",
      "22528/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 377s - loss: 0.0257\n",
      "22592/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 361s - loss: 0.0257\n",
      "22656/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 345s - loss: 0.0256\n",
      "22720/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 329s - loss: 0.0256\n",
      "22784/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 314s - loss: 0.0256\n",
      "22848/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 298s - loss: 0.0256\n",
      "22912/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 282s - loss: 0.0256\n",
      "22976/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 267s - loss: 0.0256\n",
      "23040/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 251s - loss: 0.0257\n",
      "23104/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 235s - loss: 0.0256\n",
      "23168/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 219s - loss: 0.0256\n",
      "23232/24064 [===========================>..]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 204s - loss: 0.0257\n",
      "23296/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 188s - loss: 0.0256\n",
      "23360/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 172s - loss: 0.0256\n",
      "23424/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 157s - loss: 0.0257\n",
      "23488/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 141s - loss: 0.0257\n",
      "23552/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 125s - loss: 0.0256\n",
      "23616/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 109s - loss: 0.0256\n",
      "23680/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 94s - loss: 0.0256 \n",
      "23744/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 78s - loss: 0.0256\n",
      "23808/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 62s - loss: 0.0257\n",
      "23872/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 47s - loss: 0.0256\n",
      "23936/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 31s - loss: 0.0257\n",
      "24000/24064 [============================>.]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - ETA: 15s - loss: 0.0257\n",
      "24064/24064 [==============================]\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b - 6052s - loss: 0.0257 - val_loss: 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.0001))\n",
    "model.summary()\n",
    "history = model.fit_generator(generate_train_batch(batch_size),\n",
    "                              samples_per_epoch = samples_per_epoch, nb_epoch = epoch, \n",
    "                              validation_data = generate_validation_batch(batch_size),\n",
    "                              nb_val_samples = nb_val_samples, verbose = 1, max_q_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save the model and weights\n",
    "\n",
    "# Imports\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "# Save the model to model.json\n",
    "json_string = model.to_json()\n",
    "with open('model.json', 'w') as f:\n",
    "     json.dump(json_string, f)\n",
    "\n",
    "# Save the weights to model.h5\n",
    "model.save_weights('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# CHOOSE TO IMPORT MODEL AND WEIGHTS\n",
    "# OPTIONAL: import model_train.json and model_train.h5\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Load the model from model.json\n",
    "json_data=open('model.json').read()\n",
    "json_string = json.loads(json_data)\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "#### for Otto model\n",
    "# Load the model from model.json\n",
    "#json_data=open('model_otto.json').read()\n",
    "#model = model_from_json(json_data)\n",
    "####\n",
    "\n",
    "#Load the weights from model.h5\n",
    "model.load_weights('model.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right_2016_12_01_13_45_12_716.jpg\n",
      "-0.1826526162461313\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cf1b130278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Cells below\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_angles, imgs_fname = shuffle_set(all_angles, imgs_fname)\n",
    "all_angles1 = all_angles[0:1]\n",
    "imgs_fname1 = imgs_fname[0:1]\n",
    "print(imgs_fname1[0])\n",
    "test_imgs, test_angle = load_data_batch(0,1,all_angles1, imgs_fname1,img_height,img_length)\n",
    "image = test_imgs[0]\n",
    "\n",
    "print(test_angle[0])\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1 [==============================] - 0s\n",
      "Predicted angle value:  -0.18753895163536072\n",
      "Predicted angle:  -4.688473790884018\n",
      "Expected angle value:  -0.1826526162461313\n",
      "Expected angle:  -4.566315406153282\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "image_p = image[None, :, :, :]\n",
    "predicted_angle = float(model.predict(image_p, verbose=1))\n",
    "print(\"Predicted angle value: \",predicted_angle)\n",
    "print(\"Predicted angle: \",predicted_angle/0.04)\n",
    "print(\"Expected angle value: \",test_angle[0])\n",
    "print(\"Expected angle: \",float(test_angle[0])/0.04)\n",
    "print(np.argmax(predicted_angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
